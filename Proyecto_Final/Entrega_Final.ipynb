{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Entrega Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/17z7c8CUhk1v-IEFJ4VdKm_lnzyRBY7C2?usp=sharing)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEryQGlkFMcr"
      },
      "source": [
        "<img src=\"https://becasparatodos.com/wp-content/uploads/2017/01/tec-de-monterrey-maestr%C3%ADas.jpg\" style=\"width: 400px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1RaLghWFMcx"
      },
      "source": [
        "<h2><center>Campus Ciudad de México, \n",
        "Escuela Ingeniería y Ciencias, \n",
        "Computación</center></h2>\n",
        "\n",
        "<h4><center>Course: TC2010.500 (Intelligent Systems)</center>\n",
        "<center>Professor: Mauricio Rosales Rivera</center>\n",
        "<center>Final Project - Evaluation</center></h4>\n",
        "    \n",
        "<h4><center>Date: November 13, 2020</center></h4>\n",
        "<h4><center><font color=\"red\">Submit: November 24, 2020</font></center></h4>\n",
        "\n",
        "---\n",
        "\n",
        "<h4>Grade: </h4>\n",
        "\n",
        "---\n",
        "<h4><center>Student's information</center></h4>\n",
        "<h4>Names:<strong> Carlos Julian Herrera, Ali Villegas, Alfredo Quintero </strong></h4>   \n",
        " <h4>Students ID: <strong>A01114097, A01337596, A01337630 </strong> </h4>    \n",
        " <h4>Github:</h4>\n",
        " <ul>\n",
        "  <li> <a href=\"https://github.com/JulianHerreraH/Sistemas_Inteligentes\">Github Julian\n",
        "  </a>\n",
        "  </li>\n",
        "  <li>\n",
        "  <a href=\"https://github.com/AliVillegas/Sistemas-Inteligentes\">Github Ali\n",
        "  </a>\n",
        "  </li>\n",
        "  <li>\n",
        "    <a href=\"https://github.com/alfredoqt/sistemas-inteligentes\">Github Alfredo\n",
        "    </a>\n",
        "  </li>\n",
        " </ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAwAvOy4FMcy"
      },
      "source": [
        "<center>Apegándome al Código de Ética de los Estudiantes del Tecnológico de Monterrey, me comprometo a que mi actuación en este proyecto esté regida por la honestidad académica. En congruencia con el compromiso adquirido al firmar dicho código, realizaré este proyecto de forma honesta y personal, para reflejar, a través de él, mi conocimiento y aceptar, posteriormente, la evaluación obtenida.</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt3ZwZuTFMcz"
      },
      "source": [
        "## <font color=\"brown\">Proyecto Final - Sistemas Inteligentes</font>\n",
        "\n",
        "---\n",
        "\n",
        "Indicaciones: El proyecto seleccionado será desarrollado siguiendo ciertas condiciones. Deberán seguir la estructura recomendada (pero podrán cambiar títulos, es sólo una sugerencia) y podrán añadir secciones en caso de que ser necesario.\n",
        "\n",
        "* La entrega límite de entrega de la notebook será: Martes 24 de noviembre.\n",
        "* Deberán realizar una exposición (entre 10 y 20 minutos a lo mucho), donde proporcionen una explicación acerca de la metodología implementada y los resultados obtenidos.\n",
        "\n",
        "Esta notebook deberá contener el nombre completo, matrícula y el link correspondiente al GitHub de cada integrante.\n",
        "En caso de no tener la información aquí solicitada, no se evaluará el proyecto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDhQVakBFMc0"
      },
      "source": [
        "<a id=\"general\"></a>\n",
        "# Contenido\n",
        "\n",
        "-----\n",
        "\n",
        "1. [Objetivo](#scrollTo=g8Asi86GFMc2&line=10&uniqifier=1)\n",
        "\n",
        "2. [Exploración de Datos](#scrollTo=AXe8FK-OFMc7&line=2&uniqifier=1)\n",
        "    * Detección de valores faltantes\n",
        "    * Agregando valores\n",
        "    * Visualizando datos\n",
        "    * Preprocesamiento de datos\n",
        "        * Reducción de dimensiones\n",
        "        \n",
        "-----\n",
        "3. [Selección de modelos](#scrollTo=m6QhN4TkFMc_&line=5&uniqifier=1)\n",
        "    * Aprendizaje No Supervisado / Supervisado\n",
        "        * Selección de modelo\n",
        "        * Selección de hiperparámetros\n",
        "        * Entrenamiento\n",
        "        * Prueba\n",
        "        * Resultados\n",
        "-----\n",
        "\n",
        "4. [Conclusiones](#scrollTo=WkLmBzM1FMdE&line=5&uniqifier=1)\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Asi86GFMc2"
      },
      "source": [
        "<a id=\"objectives\"></a>\n",
        "# 1. Objetivo\n",
        "\n",
        "---\n",
        "[Regresar a contenido](#scrollTo=PDhQVakBFMc0&line=8&uniqifier=1)\n",
        "\n",
        "Intentar presentar un enfoque completo para modelar problemas, que va desde el análisis exploratorio de datos hasta la aplicación de técnicas de aprendizaje supervisado y no supervisado a nuestros datos.\n",
        "\n",
        "El contenido de esta notebook está dirigido principalmente para entender mejor las etapas que se realizan en los problemas de Ciencia de Datos y Aprendizaje Máquina (y posiblemente en Aprendizaje Profundo).  \n",
        "**A continuación se presentara un breve introducción del proyecto**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe3gBur-dHr4"
      },
      "source": [
        "## **Clasificación de razas de perros usando ML**  \n",
        "El objetivo de esta notebook es presentar el proceso realizado para clasificar imagenes de perros. De manera general se siguieron los siguientes pasos para la implementación: \n",
        "- Importación de datasets\n",
        "- Detección de rosotros humanos usando OpenCV\n",
        "- Detección de perros usando una variedad de modelos preentrenados por PyTorch\n",
        "- Creacion de modelo desde cero usando una **CNN y PyTorch**\n",
        "  - Entrenamiento del modelo\n",
        "- Creacion de modelo desde cero usando una **CNN y Keras/**\n",
        "  - Entrenamiento del modelo\n",
        "- Creación de CNN usando transfer learning  \n",
        "\n",
        "En las secciones posteriores se explicará a detalle cada paso de la implemetación.\n",
        "\n",
        "----  \n",
        "Tras realizar el desarrollo, se lograron los siguientes resultados: \n",
        "- Para la CNN creada y entrenada desde cero, se obtuvo un 11% de precisón.\n",
        "- Para la CNN con transfer learning se logró un 72% de precisión.  \n",
        "\n",
        "La siguiente imagen muestra una clasificacion correcta de perro:  \n",
        "![Dog](https://drive.google.com/uc?export=view&id=1JiqGW5U-qte4BBHn9gU8ZJAZgGN4fMJ2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXe8FK-OFMc7"
      },
      "source": [
        "<a id=\"b\"></a>\n",
        "# 2. Exploración de Datos\n",
        "\n",
        "---\n",
        "[Regresar a contenido](#scrollTo=PDhQVakBFMc0&line=8&uniqifier=1)\n",
        "\n",
        "En esta sección se trata de realizar una breve explicación del conjunto de datos a utilizar. Así como tener un orden al momento de importar librerías, mostrar gráficos del EDA y preprocesamiento de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue97NjyshLot"
      },
      "source": [
        "## **Selección de datasets**  \n",
        "Para probar los modelos pre-entrenados y el entrenamiento de los creados desde cero, se utilizaron dos conjuntos de datos principales.  \n",
        "\n",
        "El primero es de **perros**, indispensable para la clasificación de razas. Cuenta con **8,351** imagenes de **133** diferentes razas de perros.  \n",
        "El conjunto de datos fue obtenido de esta dirección: \n",
        "> https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip  \n",
        "\n",
        "De igual forma se uso un dataset con imagenes de humanos. Este cuenta con **13,253** archivos. Se obtuvo de la siguiente dirección:\n",
        "> https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip  \n",
        "\n",
        "Estos conjuntos de datos se eligieron ya que contienen bastantes archivos para entrenar y validar los modelos.  \n",
        "Como un paso de validación adicional, se uso un clasificador de rostros humanos por OpenCV para evaluar una muestra del conjunto de datos:  \n",
        "```\n",
        "human_files_short = human_files[:100]\n",
        "detect_face(human_files_short)\n",
        "dog_files_short = dog_files[:200]\n",
        "detect_face(dog_files_short)\n",
        "```\n",
        "Se obtuvieron los siguientes resultados usando el clasificador:  \n",
        "- detect face in human_files: 100 / 100  \n",
        "- detect face in dog_files: 124 / 200  \n",
        "\n",
        "Para poder evaluar las razas correctamente se determino que sería necesario usar modelos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q808RF5LV7j"
      },
      "source": [
        "## **Preprocesamiento de Datos**  \n",
        "Antes de trabajar con los modelos fue necesario procesar las imagenes. Para lograr esto se llevaron acabo dos pasos principales:\n",
        "- Seleccionar objetos de datos y atributos para análisis\n",
        "- Crear y/o cambiar los atributos  \n",
        "\n",
        "Como se menciono en la parte anterior, ya se llevo acabo la seleccion de datos para análisis. Después fue necesario cambiar los atributos de las imagenes.  \n",
        "\n",
        "Se usaron las siguientes librerías para el pre-procesamiento:\n",
        "- PIL para abrir los archivos.\n",
        "- Transforms de torchvision para cambiar los atributos  \n",
        "\n",
        "```\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "input_image = Image.open(img_path)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "```\n",
        "El código presentado arriba es el encargado de abrir y procesar los archivos del dataset. Los más relevante de este procesamiento fue **ajustar el tamaño** de las imagenes a **256 pixeles**. Luego se aplico un **recorte centrado** a **224 pixeles**.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6QhN4TkFMc_"
      },
      "source": [
        "<a id=\"c\"></a>\n",
        "# 3. Selección de modelos\n",
        "\n",
        "---\n",
        "[Regresar a contenido](#scrollTo=PDhQVakBFMc0&line=8&uniqifier=1)\n",
        "\n",
        "En esta sección se trata de realizar una breve explicación de la metodología de aprendizaje automático. En caso de aplicar un **pipeline** de aprendizaje no supervisado y / o supervisado, que tenga un orden claro y expliquen el porqué de su aplicación con lo que han percibido de sus datos. \n",
        "\n",
        "El modelo seleccionado, qué parámetros o hiperparámetros eligieron, el porqué entrenaron con cierto tamaño de muestra y los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypGKhg8mbyD2"
      },
      "source": [
        "## **Descripción General de los Modelos**  \n",
        "Como se mencionó en la introducción, se usaron varios modelos y formas de entrenamiento para evaluar la mejor opción al clasificar razas de perros.  \n",
        "Es importante resaltar que todos los modelos utilizados usan la metodología de **aprendizaje supervisado**.  \n",
        "Para los modelos pre-entrenados se usaron modelos de PyTorch, fueron los siguientes: \n",
        "- VGG16\n",
        "- ShuffleNet\n",
        "- AlexNet\n",
        "- GoogLeNet  \n",
        "\n",
        "Se entrenaron dos CNN desde cero: \n",
        "- Usando PyTorch\n",
        "- Usando TensorFlow  \n",
        "\n",
        "Finalmente, se uso la técnica de Transfer Learning para entrenar otra CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaRVjaLPbDqp"
      },
      "source": [
        "## **Modelos Preentrenados**   \n",
        "#### Notebook se encuentra [aquí](https://colab.research.google.com/drive/1YEf9mC_JY8anU-SD3nW8_tua8Qx-t-cb?usp=sharing) \n",
        "Previamente se enlistaron los modelos pre-entrenados de PyTorch, a continuación se mostrara los detalles de implementación.  \n",
        "Primero se importaron las librerías necesarias:\n",
        "\n",
        "```\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "```\n",
        "\n",
        "Los modelos se obtienen por medio de PyTorch, las especificaciones se pueden encontrar [aquí](https://pytorch.org/docs/stable/torchvision/models.html). De igual forma, se utilizo CUDA, si el sistema lo permite.   \n",
        "Una vez importdas las librerias se descargaron los siguientes modelos: \n",
        "- VGG16\n",
        "- ShuffleNet\n",
        "- AlexNet\n",
        "- GoogLeNet  \n",
        "\n",
        "Estos modelos fueron entrenados con las imagenes del conjunto de datos ImageNet que contiene millones de imagenes clasificadas en diferentes clases.   \n",
        "Después de descargar los modelos, se usaron de la siguiente manera: \n",
        "\n",
        "\n",
        "```\n",
        "img = load_image(img_path)\n",
        "if use_cuda:\n",
        "    img = img.cuda()\n",
        "ret = VGG16(img)\n",
        "return torch.max(ret,1)[1].item() # predicted class index\n",
        "```\n",
        "\n",
        "En el código presentado muestra como se carga la imagen (pre-procesamiento) y luego se predice un resultado con el modelo, en este caso con VGG16.  \n",
        "Despues de predecir la imagen se obtiene el indice de la clase de ImageNet.\n",
        "Como ejemplo, usando VGG16, se obtiene el resultado correcto: \n",
        "> \"German_shepherd_dog_04945.jpg\" - ImageNet index is 235  \n",
        "> Predicted index: 235  \n",
        "\n",
        "Los otros modelos fueron implementados de igual forma.  \n",
        "Para hacer una prueba rápida de cada modelo, se comparo la precisión de cada uno para determinar si una imagen era perro. \n",
        "\n",
        "```\n",
        "Is it a dog?\n",
        "VGG16: True\n",
        "GoogLeNet: False\n",
        "ShuffleNet: False\n",
        "AlexNet: True\n",
        "```  \n",
        "\n",
        "Usando la misma imagen, solo VGG16 determino que era un perro.  Finalmente, se realizo una comparación con una muestra de 200 imagenes de perros. A continuación se muestra la grafica comparativa:  \n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Como se peude observar, VGG16 tiene una precisión de 137/200. ShuffleNet encontro 37/200 y AlexaNet 196/200\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHAdgaa2bSLK"
      },
      "source": [
        "## **CNN desde cero con PyTorch**  \n",
        "#### Notebook se encuentra [aquí](https://colab.research.google.com/drive/1YEf9mC_JY8anU-SD3nW8_tua8Qx-t-cb?usp=sharing)   \n",
        "Después de explorar los modelos pre-entrenados por PyTorch, se realizó una CNN entrenada desde cero. La red se creo usando PyTorch. A continuación se detallan los pasos tomados para implementar la CNN.  \n",
        "\n",
        "Arquitectura de la CNN:\n",
        "\n",
        "- Capa convolucional que toma 3 canales de entrada y saca 32 canales (m x n x 32). Tiene un kernel de tamaño 3 y un stride de 2, que hace que la imagen se reduzca a la mitad\n",
        "- Capa convolucional que toma 32 canales (el output de la anterior) de entrada y saca 64 canales (m x n x 64). Tiene un kernel de tamaño 3 y un stride de 2, que hace que la imagen se reduzca a la mitad.\n",
        "- Capa convolucional que toma 64 canales y los extiende a 128. Tiene un kernel de tamaño 3\n",
        "- Se aplica un max pooling al final de cada convolución con un stride de 2 para tomar las características de max value de cada segmento y reducir la imagen a la mitad\n",
        "- Se aplica ReLU como función de activación para apagar valores negativos al final de cada capa\n",
        "- Se aplica flatten de la red y luego un dropout con probabilidad de 0.3 como regularización para prevenir overfitting\n",
        "- Se aplican dos capas completamente conectadas con la activación de ReLU y un dropout con probabilidad de 0.3 para predecir las razas de perros\n",
        "\n",
        "Breakdown de la arquitectura secuencial:\n",
        "- Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
        "- ReLU\n",
        "- MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "- Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "- ReLU\n",
        "- MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "- Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "- ReLU\n",
        "- MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "- Flatten: view(-1, 7*7*128)\n",
        "- dropout(0.3)\n",
        "- Linear(in_features=6272, out_features=512, bias=True)\n",
        "- ReLU\n",
        "- dropout(0.3)\n",
        "- Linear(in_features=512, out_features=133, bias=True)\n",
        "\n",
        "> **30 epochs dan un accuracy de 18% con una cross entropy loss function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTcdXVb7bjKD"
      },
      "source": [
        "## **CNN desde cero con Keras**  \n",
        "#### Notebook se encuentra [aquí](https://colab.research.google.com/drive/1OsFhHkcDuQKW6Xp4AjiZbl1qz55k_7eW?usp=sharing)   \n",
        "Con el fin de explorar más a fondo el potencial de un modelo entrenado desde cero realizamos la implementación de otra CNN usando TensorFlow y Keras "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FznXgvRafVN1"
      },
      "source": [
        "Como siguiente paso decidimos entrenar otra CNN esta vez utilizando la librería de keras en vez de Pytorch para comparar su accuracy. \n",
        "\n",
        "Usando el mismo dataset de perros preprocesamos la información, reescalando la información de las imágenes y entrenamos nuestra CNN\n",
        "\n",
        "Utilizamos La arquitectura siguiente:\n",
        "\n",
        "4 capas convulucionales\n",
        "\n",
        "En la primera utilizamos 16 filtros y los fuimos duplicando hasta llegar a 512. \n",
        "Además utilizamos layers de pooling para reducir la complejidad y dropout para evitar overfitting del modelo. \n",
        "\n",
        "Al final obtuvimos el siguiente diseño: \n",
        "Model: \"sequential\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d (Conv2D)              (None, 224, 224, 16)      432       \n",
        "_________________________________________________________________\n",
        "batch_normalization (BatchNo (None, 224, 224, 16)      48        \n",
        "_________________________________________________________________\n",
        "activation (Activation)      (None, 224, 224, 16)      0         \n",
        "_________________________________________________________________\n",
        "max_pooling2d (MaxPooling2D) (None, 56, 56, 16)        0         \n",
        "_________________________________________________________________\n",
        "dropout (Dropout)            (None, 56, 56, 16)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 56, 56, 32)        4608      \n",
        "_________________________________________________________________\n",
        "batch_normalization_1 (Batch (None, 56, 56, 32)        96        \n",
        "_________________________________________________________________\n",
        "activation_1 (Activation)    (None, 56, 56, 32)        0         \n",
        "_________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
        "_________________________________________________________________\n",
        "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18432     \n",
        "_________________________________________________________________\n",
        "batch_normalization_2 (Batch (None, 14, 14, 64)        192       \n",
        "_________________________________________________________________\n",
        "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
        "_________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
        "_________________________________________________________________\n",
        "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
        "_________________________________________________________________\n",
        "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73728     \n",
        "_________________________________________________________________\n",
        "batch_normalization_3 (Batch (None, 4, 4, 128)         384       \n",
        "_________________________________________________________________\n",
        "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
        "_________________________________________________________________\n",
        "flatten (Flatten)            (None, 2048)              0         \n",
        "_________________________________________________________________\n",
        "dropout_3 (Dropout)          (None, 2048)              0         \n",
        "_________________________________________________________________\n",
        "dense (Dense)                (None, 512)               1049088   \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 133)               68229     \n",
        "=================================================================\n",
        "Total params: 1,215,237\n",
        "Trainable params: 1,214,757\n",
        "Non-trainable params: 480\n",
        "_________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "Posteriormente hicimos pruebas con 10 15 50 y 300 epochs para comparar cuál era más efectivo. \n",
        "\n",
        " > **Concluimos que 15 epochs arrojaban la mejor accuracy de 13.75% para nuestro modelo. Considerablemente menos accurate que una red preentrenada como se verá a continuación**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej6ZkCqpbpSn"
      },
      "source": [
        "## **CNN usando Transfer Learning** \n",
        "#### Notebook se encuentra [aquí](https://colab.research.google.com/drive/1YEf9mC_JY8anU-SD3nW8_tua8Qx-t-cb?usp=sharing)   \n",
        "Como último paso en el desarrollo del proyecto se creo un modelo a partir de ResNet50 pre-entrenado. Con la red creada desde cero como punto de partida, se uso transfer learning para tener un modelo más robusto.  \n",
        "Primero se modificaron los parametros del modelo de ResNet: \n",
        "\n",
        "\n",
        "```\n",
        "for param in model_transfer.parameters():\n",
        "    param.requires_grad = False\n",
        "model_transfer.fc = nn.Linear(2048, 133, bias=True)\n",
        "fc_parameters = model_transfer.fc.parameters()\n",
        "```  \n",
        "\n",
        "Es importante recalcar que usar ResNet50 para la transferencia de conocimiento, ya que este modelo tiene un gran rendimiento para clasificar imagenes.  \n",
        "\n",
        "El siguiente paso es especificar una función de perdida y optimización:  \n",
        "\n",
        "\n",
        "```\n",
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.SGD(model_transfer.fc.parameters(), lr=0.001)\n",
        "```  \n",
        "Para entrenar el modelo, se necesitan los siguientes paramentros: \n",
        "- Número de epochs: en este caso 30\n",
        "- Loaders\n",
        "- Model: modelo a usar, ResNet50\n",
        "- Criterion: usado para calcular la perdida\n",
        "- Optimizer: la función de optimización anterior\n",
        "- use_cuda: usar CUDA si esta disponible\n",
        "- save_path: el path donde se guardará  \n",
        "\n",
        "Después de entrenar el modelo, se probó con la funcion de ***test()*** usada para probar la CNN creada desde cero. Esto nos arrojo el siguiente resultado: \n",
        "> Test Accuracy: 77% (648/836)\n",
        "\n",
        "Finalmente, se probó el modelo de nuevo con más imagenes. A continuación se muestran dos resultados. Uno en el que detecta a una persona y describe que raza podría ser y otro donde detecta un perro y describe la raza.  \n",
        "Se probaron con varias imagenes, se muestra a continuacion la clasificación del perro de Julián y la raza de perro detectada con Ali.  \n",
        "![Dog](https://drive.google.com/uc?export=view&id=1mTmfGdV8nybymuxZBZtEUWM4Zv8eEJ-Z)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTMp4fQ-z_0S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkLmBzM1FMdE"
      },
      "source": [
        "<a id=\"d\"></a>\n",
        "# 4. Conclusiones\n",
        "\n",
        "---\n",
        "[Regresar a contenido](#scrollTo=PDhQVakBFMc0&line=8&uniqifier=1)\n",
        "\n",
        "De su análisis, qué pueden concluir? Qué posibilidades extras pudieran aplicarse o con qué finalidad realizaron el trabajo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dNysxFKglo2"
      },
      "source": [
        "Logramos tanto entrenar redes CNN desde cero como utilizando transfer learning. \n",
        "Este proyecto sirvió excelentemente para aprender los conceptos básicos de redes convolucionales. \n",
        "\n",
        "Fue posible comparar las desventajas y ventajas tanto de utilizar redes completamente desde cero como redes preentrenadas, además aprendimos a utilizar tanto la librería de keras Tensorflow como Pytorch.   \n",
        "\n",
        "Pudimos determinar que entrenar las redes desde cero requiere de varios factores y crear una red robusto no es tarea fácil. Por esto, consideramos que las redes pre-entrenadas son una herramienta muy util para poder empezar a trabajar rapidamente con ML.  \n",
        "\n",
        "Respecto a los resultados obtenidos con las CNN entrenadas desde cero, determinamos que PyTorch obtuvo los mejores resultados. Con **18%** de accuracy. Sin embargo, fue bastante util realizar otra implementacion con Keras para comparar el proceso.  \n",
        "\n",
        "Finalmente, nos dimos cuenta que usar transfer learning puede ser muy poderosos para reforzar las redes creadas desde cero con modelos ya existentes. Con esta metodologia obtuvimos un 77% de accuracy. \n",
        "\n",
        "Como trabajos y mejoras futuras, podemos buscar más tados para el entrenamientos y validación de las redes.\n",
        "\n"
      ]
    }
  ]
}